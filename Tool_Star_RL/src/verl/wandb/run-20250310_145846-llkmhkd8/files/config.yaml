wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.11.10
    cli_version: 0.19.7
    framework: huggingface
    huggingface_version: 4.49.0
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1741589926
    t:
      1:
      - 1
      - 5
      - 11
      - 30
      - 41
      - 49
      - 53
      - 55
      - 71
      - 95
      - 105
      3:
      - 13
      - 16
      - 23
      - 42
      - 55
      4: 3.11.10
      5: 0.19.7
      6: 4.49.0
      8:
      - 5
      13: linux-x86_64
data:
  desc: null
  value:
    tokenizer: null
    train_files: /home/u2024001021/ReSearch/hotpotqa/train.parquet
    val_files: /home/u2024001021/ReSearch/hotpotqa/test.parquet
    prompt_key: question
    max_prompt_length: 512
    max_response_length: 8192
    train_batch_size: 256
    val_batch_size: 1312
    return_raw_input_ids: false
    return_raw_chat: false
    apply_chat: false
    prompt_template_name: qa_template
    shuffle: true
    save_path: /home/u2024001021/ReSearch/hotpotqa/dgt_model/rollout_result.jsonl
actor_rollout_ref:
  desc: null
  value:
    hybrid_engine: true
    model:
      path: /fs/archive/share/u2024001021/huggingface_models/Qwen2.5-7B-Instruct
      external_lib: null
      override_config: {}
      enable_gradient_checkpointing: true
      use_remove_padding: true
    actor:
      strategy: fsdp
      ppo_mini_batch_size: 256
      ppo_micro_batch_size: null
      ppo_micro_batch_size_per_gpu: null
      use_dynamic_bsz: true
      ppo_max_token_len_per_gpu: 17408
      grad_clip: 1.0
      clip_ratio: 0.2
      entropy_coeff: 0.001
      use_kl_loss: true
      kl_loss_coef: 0.001
      kl_loss_type: low_var_kl
      ppo_epochs: 1
      shuffle: false
      ulysses_sequence_parallel_size: 1
      optim:
        lr: 1.0e-06
        lr_warmup_steps_ratio: 0.0
        min_lr_ratio: null
        warmup_style: constant
        total_training_steps: 390
      fsdp_config:
        wrap_policy:
          min_num_params: 0
        param_offload: false
        grad_offload: false
        optimizer_offload: false
        fsdp_size: -1
    ref:
      fsdp_config:
        param_offload: true
        wrap_policy:
          min_num_params: 0
      log_prob_micro_batch_size: null
      log_prob_micro_batch_size_per_gpu: null
      log_prob_use_dynamic_bsz: true
      log_prob_max_token_len_per_gpu: 34816
      ulysses_sequence_parallel_size: 1
    rollout:
      name: vllm_with_search
      temperature: 1.0
      top_k: -1
      top_p: 1
      prompt_length: 512
      response_length: 8192
      dtype: bfloat16
      gpu_memory_utilization: 0.6
      ignore_eos: false
      enforce_eager: true
      free_cache_engine: true
      load_format: dummy_dtensor
      tensor_model_parallel_size: 2
      max_num_batched_tokens: 8192
      max_num_seqs: 1024
      log_prob_micro_batch_size: null
      log_prob_micro_batch_size_per_gpu: null
      log_prob_use_dynamic_bsz: true
      log_prob_max_token_len_per_gpu: 34816
      disable_log_stats: true
      enable_chunked_prefill: true
      do_sample: true
      n: 5
      search_url: http://0.0.0.0:8120
critic:
  desc: null
  value:
    strategy: fsdp
    optim:
      lr: 1.0e-05
      lr_warmup_steps_ratio: 0.0
      min_lr_ratio: null
      warmup_style: constant
      total_training_steps: 390
    model:
      path: ~/models/deepseek-llm-7b-chat
      tokenizer_path: /fs/archive/share/u2024001021/huggingface_models/Qwen2.5-7B-Instruct
      override_config: {}
      external_lib: null
      enable_gradient_checkpointing: true
      use_remove_padding: false
      fsdp_config:
        param_offload: false
        grad_offload: false
        optimizer_offload: false
        wrap_policy:
          min_num_params: 0
        fsdp_size: -1
    ppo_mini_batch_size: 256
    ppo_micro_batch_size: null
    ppo_micro_batch_size_per_gpu: null
    forward_micro_batch_size: null
    forward_micro_batch_size_per_gpu: null
    use_dynamic_bsz: true
    ppo_max_token_len_per_gpu: 32768
    forward_max_token_len_per_gpu: 32768
    ulysses_sequence_parallel_size: 1
    ppo_epochs: 1
    shuffle: false
    grad_clip: 1.0
    cliprange_value: 0.5
reward_model:
  desc: null
  value:
    enable: false
    strategy: fsdp
    model:
      input_tokenizer: /fs/archive/share/u2024001021/huggingface_models/Qwen2.5-7B-Instruct
      path: ~/models/FsfairX-LLaMA3-RM-v0.1
      external_lib: null
      use_remove_padding: false
      fsdp_config:
        min_num_params: 0
        param_offload: false
        fsdp_size: -1
    micro_batch_size: null
    micro_batch_size_per_gpu: null
    max_length: null
    ulysses_sequence_parallel_size: 1
    use_dynamic_bsz: true
    forward_max_token_len_per_gpu: 32768
    reward_manager: qa
algorithm:
  desc: null
  value:
    gamma: 1.0
    lam: 1.0
    adv_estimator: grpo
    kl_penalty: kl
    kl_ctrl:
      type: fixed
      kl_coef: 0.001
trainer:
  desc: null
  value:
    total_epochs: 10
    total_training_steps: null
    project_name: hotpotqa
    experiment_name: dgt
    logger:
    - console
    - wandb
    val_generations_to_log_to_wandb: 0
    nnodes: 1
    n_gpus_per_node: 4
    save_freq: 10
    resume_mode: auto
    resume_from_path: false
    test_freq: 10
    critic_warmup: 0
    default_hdfs_dir: null
    remove_previous_ckpt_in_save: false
    del_local_ckpt_after_load: false
    default_local_dir: /home/u2024001021/ReSearch/hotpotqa/dgt_model
    val_before_train: true
